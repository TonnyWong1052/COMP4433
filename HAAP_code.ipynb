{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import python package"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.impute import SimpleImputer\n","\n","from mlxtend.frequent_patterns import apriori\n","from mlxtend.frequent_patterns import association_rules\n","\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n","\n","from mlxtend.frequent_patterns import apriori, association_rules\n","from mlxtend.preprocessing import TransactionEncoder\n","\n","from sklearn.decomposition import PCA\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.mixture import GaussianMixture\n","from sklearn.cluster import MeanShift\n","\n","from pycaret.regression import setup, compare_models\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["second_df = pd.read_csv('/Users/tomleung/Downloads/Cardiovascular_Disease_Dataset.csv')\n","main_df = pd.read_csv('/Users/tomleung/Downloads/heart.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["main_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["second_df"]},{"cell_type":"markdown","metadata":{},"source":["# Data Pre-Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# patientid is not necassary\n","second_df = second_df.drop('patientid', axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# rename the column of second_df\n","column_mapping = {\n","    \"gender\" : \"sex\",\n","    \"chestpain\" : \"cp\",\n","    \"restingBP\" : \"trtbps\",\n","    \"serumcholestrol\" : \"chol\",\n","    \"fastingbloodsugar\" : \"fbs\",\n","    \"restingrelectro\" : \"restecg\",\n","    \"maxheartrate\" : \"thalachh\",\n","    \"exerciseangia\" : \"exng\",\n","    \"slope\" : \"slp\",\n","    \"noofmajorvessels\" : \"caa\",\n","    \"thal\" : \"thall\",\n","    \"target\" : \"output\"\n","}\n","second_df = second_df.rename(columns=column_mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["second_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Merging the datasets\n","df = pd.concat([second_df, main_df], axis=0, join='outer', ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Removing outliers\n","Q1 = df.quantile(0.25)\n","Q3 = df.quantile(0.75)\n","IQR = Q3 - Q1\n","\n","print(f\"Original DataFrame shape: {df.shape}\")\n","\n","df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n","\n","print(f\"DataFrame shape after outlier removal: {df.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.shape\n","# check how many row of data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.isnull().sum() \n","#check any missing value"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.duplicated().sum()\n","# sum of duplicate data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.drop_duplicates(keep='first',inplace=True)\n","# remove duplicate data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# predict the missing values \n","thal_present = df[df['thall'].notnull()]\n","thal_missing = df[df['thall'].isnull()]\n","\n","X = thal_present.drop('thall', axis=1)\n","y = thal_present['thall']\n","\n","imputer = SimpleImputer(strategy='mean')\n","X_imputed = imputer.fit_transform(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=0)\n","\n","model = LinearRegression()\n","model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Replace missing 'thal' values with the predicted values\n","thal_missing_imputed = imputer.transform(thal_missing.drop('thall', axis=1))\n","\n","thal_predicted = model.predict(thal_missing_imputed)\n","\n","thal_predicted_rounded = thal_predicted.round(3)\n","\n","df.loc[df['thall'].isnull(), 'thall'] = thal_predicted_rounded"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.describe()\n","# show statistical data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["# Association Rule Mining"]},{"cell_type":"markdown","metadata":{},"source":["## Data Description\n","age - age in years\n","\n","sex - sex (1 = male; 0 = female)\n","\n","cp - chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 0 = asymptomatic)\n","\n","trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n","\n","chol - serum cholestoral in mg/dl\n","\n","fbs - fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n","\n","restecg - resting electrocardiographic results (1 = normal; 2 = having ST-T wave abnormality; 0 = hypertrophy)\n","\n","thalach - maximum heart rate achieved\n","\n","exang - exercise induced angina (1 = yes; 0 = no)\n","\n","oldpeak - ST depression induced by exercise relative to rest\n","\n","slope - the slope of the peak exercise ST segment (2 = upsloping; 1 = flat; 0 = downsloping)\n","\n","ca - number of major vessels (0-3) colored by flourosopy\n","\n","thal - 2 = normal; 1 = fixed defect; 3 = reversable defect\n","\n","num - the predicted attribute - diagnosis of heart disease (angiographic disease status) (Value 0 = < diameter narrowing; Value 1 = > 50% diameter narrowing)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_arm = df.copy()\n","# Binning age into categories\n","df_arm['age'] = pd.cut(df['age'], bins=[0, 20, 40, 60, 100], labels=['0_To_20', '21_To_40','41_To_60', '60_above'])\n","df_arm['sex'] = pd.cut(df['sex'], bins=[-1, 0, 1], labels=['Female', 'Male'])\n","df_arm['cp'] = pd.cut(df['cp'], bins=[-1, 0, 1, 2, 3], labels=['asymptomatic', 'typical_angina', 'atypical_angina', 'non-anginal_pain'])\n","df_arm['thall'] = pd.cut(df['thall'], bins=[0, 1, 2, 3], labels=['fixed_defect', 'thal_normal', 'reversable_defect'])\n","df_arm['fbs'] = pd.cut(df['fbs'], bins=[-1, 0, 1], labels=['fasting_blood_sugar<=120 mg/dl', 'fasting_blood_sugar>120_mg/dl'])\n","df_arm['restecg'] = pd.cut(df['restecg'], bins=[-1, 0, 1, 2], labels=['hypertrophy', 'normal', 'having_ST-T_wave_abnormality'])\n","df_arm['exng'] = pd.cut(df['exng'], bins=[-1, 0, 1], labels=['not_exercise_induced_angina', 'exercise_induced_angina'])\n","\n","df_arm['trtbps'] = pd.cut(df['trtbps'], 3, labels=['low_bp', 'medium_bp', 'high_bp'])\n","df_arm['chol'] = pd.cut(df['chol'], 3, labels=['low_chol', 'medium_chol', 'high_chol'])\n","df_arm['thalachh'] = pd.cut(df['thalachh'], 3, labels=['low_hr', 'medium_hr', 'high_hr'])\n","df_arm['oldpeak'] = pd.cut(df['oldpeak'], 3, labels=['low_op', 'medium_op', 'high_op'])\n","df_arm['output'] = pd.cut(df['output'], bins=[-1, 0, 1], labels=['more_chance_of_heart_attack', 'less_chance_of_heart_attack'])\n","df_arm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# rename all of value name, make the value clearly, allow easy to understand\n","def rename_values(df):\n","    for col in df.columns:\n","        if col not in ['Unnamed', 'thall']:\n","            df[col] = df[col].apply(lambda x: f\"{col}_{str(x)}\" if pd.notnull(x) else x)\n","    return df\n","\n","data_categorical = rename_values(df_arm)\n","data_categorical.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_asso_rule = data_categorical.copy()\n","data_asso_rule = data_asso_rule.astype(str)\n","data_asso_rule = data_asso_rule.values.tolist()\n","# Create TransactionEncoder object\n","te = TransactionEncoder()\n","\n","# Perform One-hot encoding\n","te_ary = te.fit_transform(data_asso_rule)\n","\n","# Convert the sparse matrix to a dense array\n","data6 = pd.DataFrame(te_ary, columns=te.columns_)\n","\n","frequent_itemsets = apriori(data6, min_support=0.3, use_colnames=True)\n","rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.4)\n","\n","filtered_rules = rules[rules['consequents'].astype(str).str.contains(\"|\".join(['output_more_chance_of_heart_attack', 'output_less_chance_of_heart_attack']))]\n","\n","bundles = []\n","for index, row in filtered_rules.iterrows():\n","    antecedents = ', '.join(list(row['antecedents']))\n","    consequents = ', '.join(list(row['consequents']))\n","    support = row['support']\n","    confidence = row['confidence']\n","    lift = row['lift']\n","    bundle = f\"{antecedents} --> {consequents} [Support: {support:.3f}, Confidence: {confidence:.3f}, Lift: {lift:.3f}]\"\n","    bundles.append(bundle)\n","\n","# Print each bundle\n","for bundle in bundles:\n","    print(bundle)"]},{"cell_type":"markdown","metadata":{},"source":["## Data Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n","\n","sns.histplot(df['age'], bins=20, kde=True, ax=axes[0, 0])\n","axes[0, 0].set_title('Age Distribution')\n","\n","sns.histplot(df['trtbps'], bins=20, kde=True, ax=axes[0, 1])\n","axes[0, 1].set_title('Resting Blood Pressure Distribution')\n","\n","sns.histplot(df['chol'], bins=20, kde=True, ax=axes[1, 0])\n","axes[1, 0].set_title('Cholesterol Distribution')\n","\n","sns.histplot(df['thalachh'], bins=20, kde=True, ax=axes[1, 1])\n","axes[1, 1].set_title('Max Heart Rate Distribution')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# categorical variables\n","fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n","\n","sns.countplot(x='sex', data=df, ax=axes[0, 0])\n","axes[0, 0].set_title('Gender Distribution')\n","axes[0, 0].set_xticklabels(['Female', 'Male'])\n","\n","sns.countplot(x='cp', data=df, ax=axes[0, 1])\n","axes[0, 1].set_title('Chest Pain Type Distribution')\n","\n","sns.countplot(x='fbs', data=df, ax=axes[1, 0])\n","axes[1, 0].set_title('Fasting Blood Sugar > 120 mg/dl Distribution')\n","axes[1, 0].set_xticklabels(['False', 'True'])\n","\n","sns.countplot(x='exng', data=df, ax=axes[1, 1])\n","axes[1, 1].set_title('Exercise Induced Angina Distribution')\n","axes[1, 1].set_xticklabels(['No', 'Yes'])\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Creating a heatmap to visualize the correlation between variables\n","plt.figure(figsize=(9, 7))\n","correlation_matrix = df.corr()\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n","plt.title('Correlation Matrix')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# show data distributions\n","fig, axes = plt.subplots(2, 2, figsize=(9, 7))\n","\n","sns.boxplot(x=df['age'], ax=axes[0, 0])\n","axes[0, 0].set_title('Box Plot of Age')\n","\n","sns.boxplot(x=df['trtbps'], ax=axes[0, 1])\n","axes[0, 1].set_title('Box Plot of Resting Blood Pressure (trtbps)')\n","\n","sns.boxplot(x=df['chol'], ax=axes[1, 0])\n","axes[1, 0].set_title('Box Plot of Cholesterol (chol)')\n","\n","sns.boxplot(x=df['thalachh'], ax=axes[1, 1])\n","axes[1, 1].set_title('Box Plot of Max Heart Rate (thalachh)')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Data Processing"]},{"cell_type":"markdown","metadata":{},"source":["## Data Spliting"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X = df.drop('output',axis='columns')\n","y = df['output']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=0)\n","X_test = main_df.drop('output',axis='columns')\n","y_test = main_df['output']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from imblearn.over_sampling import SMOTE\n","# smote = SMOTE(random_state=0)\n","# X_train_pca, y_train = smote.fit_resample(X_train_pca, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reduce data dimensions using PCA - reduce 2 dimensions\n","pca = PCA(n_components=2)\n","X_train_pca = pca.fit_transform(X_train_scaled)\n","X_test_pca = pca.transform(X_test_scaled)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Implement K-Means with different number of clusters\n","scores = {}\n","for k in range(2, 10):\n","    kmeans = KMeans(n_clusters=k, random_state=0)\n","    cluster_labels = kmeans.fit_predict(X_train_pca)\n","    silhouette_avg = silhouette_score(X_train_pca, cluster_labels)\n","    scores[k] = silhouette_avg\n","\n","# Finding the optimal number of clusters\n","optimal_k = max(scores, key=scores.get)\n","optimal_score = scores[optimal_k]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Agglomerative Clustering and DBSCAN, then use other clustering models\n","models = {\n","    \"AgglomerativeClustering\": AgglomerativeClustering(n_clusters=3),\n","    \"DBSCAN\": DBSCAN(eps=0.5, min_samples=5),\n","    \"MeanShift\" : MeanShift(bandwidth=0.5), \n","    \"GaussianMixture\": GaussianMixture(n_components=5)\n","}\n","\n","for model_name, model in models.items():\n","    cluster_labels = model.fit_predict(X_train_pca)\n","    \n","    silhouette_avg = silhouette_score(X_train_pca, cluster_labels)\n","    \n","    print(f'{model_name} Silhouette Scores is {silhouette_avg}')\n","print(f'K-Means clusting: Optimal k equal {optimal_k} with Silhouette Scores is {optimal_score}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["label_range = {2: 0.30, 3: 0.45, 4: 0.55, 5: 0.35, 6: 0.25, 7: 0.20, 8: 0.15, 9: 0.10}\n","\n","optimal_k_example = max(label_range, key=label_range.get)\n","\n","kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n","cluster_labels = kmeans.fit_predict(X_test_pca)\n","\n","plt.figure(figsize=(10, 6))\n","plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=cluster_labels, cmap='viridis', marker='o')\n","plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red', marker='X', label='Centroids')\n","plt.title(f'Cluster Visualization')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Model training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["kmeans = KMeans(n_clusters=optimal_k, n_init=10, random_state=0)\n","X_train['cluster_label'] = kmeans.fit_predict(X_train_pca)\n","X_test['cluster_label'] = kmeans.predict(X_test_pca)\n","\n","x_test = X_test\n","x_train = X_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["_ = setup(data=pd.concat([X_train, y_train], axis=1), target='output')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression()\n","model.fit(x_train, y_train)\n","  \n","predicted = model.predict(x_test)\n","LogisticRegression_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"Logistic Regression accuracy: %.2f%%\" % LogisticRegression_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.svm import SVC\n","\n","model = SVC()\n","model.fit(x_train, y_train)\n","  \n","predicted = model.predict(x_test)\n","SVC_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"SVC accuracy: %.2f%%\" % SVC_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","model = GradientBoostingClassifier()\n","model.fit(x_train, y_train)\n","  \n","predicted = model.predict(x_test)\n","GradientBoostingClassifier_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"GradientBoosting Classifier accuracy: %.2f%%\" % GradientBoostingClassifier_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","model = RandomForestClassifier()\n","\n","model.fit(x_train, y_train)\n","\n","predicted = model.predict(x_test)\n","RandomForestClassifier_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"Random Forest accuracy: %.2f%%\" % RandomForestClassifier_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","model = DecisionTreeClassifier()\n","\n","model.fit(x_train, y_train)\n","\n","predicted = model.predict(x_test)\n","DecisionTreeClassifier_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"Decision Tree Classifier accuracy: %.2f%%\" % DecisionTreeClassifier_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","model = KNeighborsClassifier(n_neighbors=11, p=2)\n","\n","model.fit(x_train, y_train)\n","\n","predicted = model.predict(x_test)\n","KNeighborsClassifier_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"KNeighbors Classifier accuracy: %.2f%%\" % KNeighborsClassifier_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","\n","model = GaussianNB()\n","\n","model.fit(x_train, y_train)\n","\n","predicted = model.predict(x_test)\n","GaussianNB_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"GaussianNB accuracy: %.2f%%\" % GaussianNB_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","model = AdaBoostClassifier()\n","\n","model.fit(x_train, y_train)\n","\n","predicted = model.predict(x_test)\n","AdaBoostClassifier_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"AdaBoost Classifier accuracy: %.2f%%\" % AdaBoostClassifier_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.neural_network import MLPClassifier\n","\n","model = MLPClassifier()\n","\n","model.fit(x_train, y_train)\n","\n","predicted = model.predict(x_test)\n","MLPClassifier_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"MLP Classifier accuracy: %.2f%%\" % MLPClassifier_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import xgboost as xgb\n","\n","model = xgb.XGBClassifier(objective='binary:logistic', random_state=2, learning_rate=0.4)\n","\n","model.fit(x_train, y_train)\n","\n","predicted = model.predict(x_test)\n","xgb_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"XGB Accuracy: %.2f%%\" % xgb_score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn import tree\n","# remark: maybe accruacy score seems not a good apporach to evaluate the accuracy of decision tree\n","model = tree.DecisionTreeClassifier(random_state=0)\n","model.fit(x_train, y_train)\n","\n","predicted = model.predict(x_test)\n","dtc_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"Decision TreeC Classifier Accuracy: %.2f%%\" % dtc_score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# decision tree visuliation\n","plt.figure(figsize=(30, 16))\n","tree.plot_tree(model, filled=True)\n","plt.title(\"Decision Tree\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import catboost\n","from catboost import CatBoostClassifier\n","\n","cat_clf = CatBoostClassifier()\n","cat_clf.fit(X_train, y_train)\n","\n","predicted = cat_clf.predict(x_test)\n","cat_score = accuracy_score(y_test, predicted) * 100.0\n","print(\"catboost Accuracy: %.2f%%\" % cat_score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import ExtraTreesRegressor\n","from sklearn.metrics import r2_score\n","\n","model = ExtraTreesRegressor(random_state=0)\n","model.fit(X_train, y_train)\n","predicted = model.predict(x_test)\n","etr_score = r2_score(y_test, predicted) * 100\n","print(\"Extra Trees Regressor Accuracy: %.2f%%\" % etr_score)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["models = ['Logistic Regression', 'Gradient Boosting', 'SVC', 'Random Forest Classifier', \n","          'Decision Tree Classifier', 'KNeighbors Classifier', 'GaussianNB', 'AdaBoostClassifier',\n","         'MLPClassifier', 'XGB', 'DecisionTreeClassifier', 'CatBoostClassifier']\n","\n","scores = [LogisticRegression_score, GradientBoostingClassifier_score, SVC_score, \n","          RandomForestClassifier_score, DecisionTreeClassifier_score, KNeighborsClassifier_score,\n","         GaussianNB_score, AdaBoostClassifier_score, MLPClassifier_score, xgb_score, dtc_score, cat_score]\n","\n","plt.figure(figsize=(14, 8))  \n","plt.barh(models, scores)  \n","plt.ylabel('Model')\n","plt.xlabel('Accuracy (%)')\n","plt.title('Model Accuracy Comparison')\n","plt.xlim([0, 100])  \n","for i in range(len(scores)):\n","    plt.text(scores[i], i, f'{scores[i]:.2f}%', va='center')  \n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["xgb_clf = xgb.XGBClassifier(random_state=0)\n","rf_clf = RandomForestClassifier(random_state=0)\n","gb_clf = GradientBoostingClassifier(learning_rate=0.5, max_depth=10, max_features=0.7500000000000001, min_samples_leaf=14, min_samples_split=14, n_estimators=100, subsample=0.9500000000000001)\n","#cat_clf = CatBoostClassifier()\n","\n","xgb_clf.fit(x_train, y_train)\n","rf_clf.fit(x_train, y_train)\n","gb_clf.fit(x_train, y_train)\n","#cat_clf.fit(X_train, y_train)\n","\n","xgb_pred = xgb_clf.predict(X_test)\n","rf_pred = rf_clf.predict(X_test)\n","gb_pred = gb_clf.predict(X_test)\n","cat_clf_pred = cat_clf.predict(X_test)\n","\n","combined_pred = []\n","for i in range(len(X_test)):\n","    votes = [xgb_pred[i], rf_pred[i], gb_pred[i], cat_clf_pred[i]]\n","    combined_pred.append(max(set(votes), key=votes.count))\n","\n","combined_accuracy = accuracy_score(y_test, combined_pred) * 100\n","#print('Combined Model Accuracy: %.2f'% combined_accuracy)\n","print(f'Combined Model Accuracy: {combined_accuracy}%')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["compare_models()"]},{"cell_type":"markdown","metadata":{},"source":["<!-- from tpot import TPOTClassifier\n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","\n","digits = load_digits()\n","\n","tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2)\n","tpot.fit(x_train, y_train)\n","print(\"TPOT Accuracy:\", tpot.score(x_train, y_train)) -->"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":216167,"sourceId":477177,"sourceType":"datasetVersion"},{"datasetId":1226038,"sourceId":2047221,"sourceType":"datasetVersion"},{"datasetId":4125346,"sourceId":7146314,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
